import Flutter
import UIKit
import AVFoundation

@objc public class MinfoSdkPlugin: NSObject, FlutterPlugin {
    private var minfoChannel: FlutterMethodChannel?
    private let TAG = "MinfoSDK-iOS"

    public static func register(with registrar: FlutterPluginRegistrar) {
        let channel = FlutterMethodChannel(name: "com.gzone.campaign/audioCapture", binaryMessenger: registrar.messenger())
        let instance = MinfoSdkPlugin()
        instance.minfoChannel = channel
        registrar.addMethodCallDelegate(instance, channel: channel)
    }

    public func handle(_ call: FlutterMethodCall, result: @escaping FlutterResult) {
        switch call.method {
        case "initialise":
            result(["version": "2.3.0-ios", "available": true])
        case "startDetection", "startAudioCapture":
            handleStartDetection(result: result)
        case "stopDetection", "stopAudioCapture":
            handleStopDetection(result: result)
        default:
            result(FlutterMethodNotImplemented)
        }
    }

    private func handleStartDetection(result: @escaping FlutterResult) {
        let status = AVAudioSession.sharedInstance().recordPermission
        if status == .granted {
            startSCS(result: result)
        } else {
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                DispatchQueue.main.async {
                    if granted { self.startSCS(result: result) }
                    else { result(FlutterError(code: "PERMISSION_DENIED", message: "Microphone access denied", details: nil)) }
                }
            }
        }
    }

    private func startSCS(result: @escaping FlutterResult) {
        do {
            // 1. ACTIVATION de l'AudioSession (Critique sur iOS)
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playAndRecord, mode: .measurement, options: [.defaultToSpeaker])
            try audioSession.setActive(true)
            print("\(TAG): ‚úÖ AudioSession activ√©e")

            let wrapper = SCSManagerWrapper.shared()

            // 2. PR√âPARATION (Activation moteur) - V√©rifier l'initialisation des ressources
            wrapper.prepareWithSettings()
            print("\(TAG): ‚úÖ Moteur pr√©par√©")

            // 3. √âCOUTEUR (Control) - On nettoie l'ancien avant d'ajouter
            NotificationCenter.default.removeObserver(self, name: NSNotification.Name("MinfoDetectionForFlutter"), object: nil)
            NotificationCenter.default.addObserver(
                forName: NSNotification.Name("MinfoDetectionForFlutter"),
                object: nil,
                queue: .main
            ) { [weak self] notification in
                if let data = notification.userInfo?["detectedData"] as? [Any] {
                    print("\(self?.TAG ?? "MinfoSDK-iOS"): üéØ Signal d√©tect√©: \(data)")
                    self?.minfoChannel?.invokeMethod("onDetectedId", arguments: data)
                }
            }
            print("\(TAG): ‚úÖ √âcouteur (notifications) configur√©")

            // 4. D√âMARRAGE DU D√âCODAGE
            print("\(TAG): üöÄ D√©marrage du d√©codage...")
            wrapper.startSearching()
            print("\(TAG): ‚úÖ D√©codage en cours")
            
            result(["success": true])
        } catch {
            let errorMsg = "Erreur AudioSession: \(error.localizedDescription)"
            print("\(TAG): ‚ùå \(errorMsg)")
            result(FlutterError(code: "AUDIO_ERROR", message: errorMsg, details: nil))
        }
    }

    private func handleStopDetection(result: @escaping FlutterResult) {
        SCSManagerWrapper.shared().stopSearching()
        try? AVAudioSession.sharedInstance().setActive(false)
        result(["success": true])
    }
}