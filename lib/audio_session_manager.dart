
import 'package:permission_handler/permission_handler.dart';
import 'package:audio_session/audio_session.dart';
import 'package:minfo_sdk/minfo_sdk.dart';
import 'package:minfo_sdk/ios_audio_debug.dart';
import 'dart:io';
import 'dart:developer' as developer;

class AudioSessionManager {
  static Future<bool> setupAudioSessionForMinfo() async {
    developer.log('ğŸµ Configuration session audio pour Minfo...');
    
    try {
      final session = await AudioSession.instance;
      
      // Configuration spÃ©cifique pour la dÃ©tection audio
      await session.configure(AudioSessionConfiguration(
        avAudioSessionCategory: AVAudioSessionCategory.playAndRecord,
        avAudioSessionCategoryOptions: AVAudioSessionCategoryOptions.defaultToSpeaker,
        avAudioSessionMode: AVAudioSessionMode.measurement,
        avAudioSessionRouteSharingPolicy: AVAudioSessionRouteSharingPolicy.defaultPolicy,
        avAudioSessionSetActiveOptions: AVAudioSessionSetActiveOptions.none,
        androidAudioAttributes: const AndroidAudioAttributes(
          contentType: AndroidAudioContentType.speech,
          flags: AndroidAudioFlags.none,
          usage: AndroidAudioUsage.voiceCommunication,
        ),
        androidAudioFocusGainType: AndroidAudioFocusGainType.gain,
        androidWillPauseWhenDucked: false,
      ));
      
      // Debug spÃ©cifique iOS
      if (Platform.isIOS) {
        developer.log('ğŸµ ğŸ“± Debug session audio iOS...');
        await IOSAudioDebug.logAudioSessionDetails();
        await IOSAudioDebug.optimizeForAudioDetection();
      }
      
      developer.log('ğŸµ âœ… Session audio configurÃ©e avec succÃ¨s');
      return true;
    } catch (e) {
      developer.log('ğŸµ âŒ Erreur configuration session audio: $e');
      return false;
    }
  }
  
  static Future<bool> requestMicrophoneWithAudioSession() async {
    developer.log('ğŸ¤ DÃ©but processus complet permission + session audio', name: 'minfo.permissions');
    
    // 1. VÃ©rifier permission microphone
    final status = await Permission.microphone.status;
    developer.log('ğŸ¤ Statut permission: $status', name: 'minfo.permissions');
    
    if (status.isPermanentlyDenied) {
      developer.log('ğŸ¤ âŒ Permission refusÃ©e dÃ©finitivement', name: 'minfo.permissions');
      await openAppSettings();
      return false;
    }
    
    // 2. Demander permission si nÃ©cessaire
    if (!status.isGranted) {
      developer.log('ğŸ¤ ğŸ“± Demande permission...', name: 'minfo.permissions');
      final result = await Permission.microphone.request();
      developer.log('ğŸ¤ ğŸ“± RÃ©sultat: $result', name: 'minfo.permissions');
      
      if (!result.isGranted) {
        developer.log('ğŸ¤ âŒ Permission refusÃ©e par utilisateur', name: 'minfo.permissions');
        return false;
      }
    }
    
    // 3. Attendre iOS
    await Future.delayed(Duration(milliseconds: 500));
    
    // 4. Configurer session audio APRÃˆS permission
    developer.log('ğŸ¤ âœ… Permission accordÃ©e, configuration session audio...', name: 'minfo.permissions');
    final audioConfigured = await setupAudioSessionForMinfo();
    
    if (!audioConfigured) {
      developer.log('ğŸ¤ âŒ Ã‰chec configuration session audio', name: 'minfo.permissions');
      return false;
    }
    
    // 5. VÃ©rification finale
    final finalStatus = await Permission.microphone.status;
    developer.log('ğŸ¤ Statut final: $finalStatus', name: 'minfo.permissions');
    
    return finalStatus.isGranted;
  }
}

class MinfoDetectionManager {
  static Future<bool> startDetectionWithProperSetup() async {
    developer.log('ğŸš€ DÃ©but dÃ©tection Minfo avec setup complet');
    
    try {
      // 1. Setup permissions + audio session
      final hasAccess = await AudioSessionManager.requestMicrophoneWithAudioSession();
      
      if (!hasAccess) {
        developer.log('ğŸš€ âŒ Pas d\'accÃ¨s audio, arrÃªt');
        return false;
      }
      
      // 2. Initialiser le moteur AudioQR AVANT de dÃ©marrer
      developer.log('ğŸš€ ğŸ”§ Initialisation du moteur AudioQR...');
      final engineInitialized = await MinfoSdk.instance.audioEngine.initialise();
      
      if (!engineInitialized) {
        developer.log('ğŸš€ âŒ Ã‰chec initialisation moteur AudioQR');
        return false;
      }
      
      developer.log('ğŸš€ âœ… Moteur AudioQR initialisÃ©');
      
      // 3. Configurer le listener
      developer.log('ğŸš€ ğŸ“¡ Configuration du listener...');
      MinfoSdk.instance.configureListener();
      
      // 4. Attendre stabilisation iOS
      developer.log('ğŸš€ â³ Attente stabilisation iOS...');
      await Future.delayed(Duration(milliseconds: 1000));
      
      // 5. DÃ©marrer dÃ©tection Minfo
      developer.log('ğŸš€ ğŸ¯ DÃ©marrage dÃ©tection Minfo...');
      await MinfoSdk.instance.audioEngine.startDetection();
      
      developer.log('ğŸš€ âœ… DÃ©tection dÃ©marrÃ©e avec succÃ¨s');
      return true;
      
    } catch (e) {
      developer.log('ğŸš€ âŒ Erreur dÃ©tection: $e');
      return false;
    }
  }
}
